{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSUS - CSc 177-02 Data Warehousing and Data Mining - Project 1: Clustering  \n",
    "### 2016 U.S. presidential election Twitter analysis  \n",
    "\n",
    "**Group members: Aaron Enberg, Nima Sarrafzadeh, Kyne Liu**  \n",
    "**Professor: Haiquan (Victor) Chen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import (\n",
    "    preprocessing,  \n",
    "    cluster as sk_cluster,\n",
    "    metrics as metrics\n",
    ")\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    "    GridSearchCV\n",
    ")\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "import gc\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column_names = ['name', 'screen_name', 'user_id', \n",
    "                'followers_count', 'friends_count', \n",
    "                'location', 'description', 'created_at', \n",
    "                'status_id', 'language', 'place', \n",
    "                'retweet_count', 'favorite_count', 'text']\n",
    "\n",
    "tweets = pd.read_table('data/clinton_trump_tweets.txt', names=column_names, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5250980, 14)\n",
      "name               object\n",
      "screen_name        object\n",
      "user_id            int64 \n",
      "followers_count    int64 \n",
      "friends_count      int64 \n",
      "location           object\n",
      "description        object\n",
      "created_at         object\n",
      "status_id          int64 \n",
      "language           object\n",
      "place              object\n",
      "retweet_count      int64 \n",
      "favorite_count     int64 \n",
      "text               object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(tweets.shape)\n",
    "print(tweets.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1519696717</td>\n",
       "      <td>132</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>@NWAJimmy I've read it now though brother. Was pretty spot on Lots of bright spots but a lot to work on. Exactly as an exhibition should be!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109945090</td>\n",
       "      <td>2154</td>\n",
       "      <td>2034</td>\n",
       "      <td>1937</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @wikileaks: New poll puts Pirate Party on course to win Iceland's national elections on Saturday. https://t.co/edTqjeJaQ6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1450086582</td>\n",
       "      <td>797</td>\n",
       "      <td>1188</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@gaystoner821 I think New Orleans spoiled me with food. I need to try and branch out in BR.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>167177185</td>\n",
       "      <td>204</td>\n",
       "      <td>448</td>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @LOLGOP: ACA needs fixes but know da facts:  *70% can get covered in marketplaces for under $75/month  *Hikes affect 3% *GOP will uninsu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1191022351</td>\n",
       "      <td>775</td>\n",
       "      <td>154</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @FastCompany: Alphabet shares soar on better-than-expected earnings as mobile video strategy pays off https://t.co/bokbXngMJt https://t.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  followers_count  friends_count  retweet_count  favorite_count  \\\n",
       "0  1519696717  132              263            0              1                \n",
       "1  109945090   2154             2034           1937           0                \n",
       "2  1450086582  797              1188           0              0                \n",
       "3  167177185   204              448            891            0                \n",
       "4  1191022351  775              154            7              0                \n",
       "\n",
       "                                                                                                                                           text  \n",
       "0  @NWAJimmy I've read it now though brother. Was pretty spot on Lots of bright spots but a lot to work on. Exactly as an exhibition should be!  \n",
       "1  RT @wikileaks: New poll puts Pirate Party on course to win Iceland's national elections on Saturday. https://t.co/edTqjeJaQ6                  \n",
       "2  @gaystoner821 I think New Orleans spoiled me with food. I need to try and branch out in BR.                                                   \n",
       "3  RT @LOLGOP: ACA needs fixes but know da facts:  *70% can get covered in marketplaces for under $75/month  *Hikes affect 3% *GOP will uninsu   \n",
       "4  RT @FastCompany: Alphabet shares soar on better-than-expected earnings as mobile video strategy pays off https://t.co/bokbXngMJt https://t.   "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.drop(['name', 'screen_name', \n",
    "            'followers_count', \n",
    "            'friends_count', \n",
    "            'location', \n",
    "            'description', \n",
    "            'created_at',\n",
    "            'status_id', \n",
    "            'language', \n",
    "            'place', \n",
    "            'retweet_count', \n",
    "            'favorite_count'], axis=1, inplace=True)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lines that start with \"RT\" followed by a space\n",
    "pattern = r'^RT\\s'\n",
    " \n",
    "# matches retweets and removes them\n",
    "tweets = tweets[tweets.text.str.match(pattern) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2416818, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract all handles and hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# match all hashtags and handles in a tweet, ignoring possible email addresses\n",
    "pattern = r'(?<=^|(?<=[^a-zA-Z0-9-\\.]))@([A-Za-z_]+[A-Za-z0-9_]+)|(?<=^|(?<=[^a-zA-Z0-9-\\.]))#([A-Za-z_]+[A-Za-z0-9_]+)'\n",
    "\n",
    "\"\"\" returns a DataFrame with a MultiIndex:\n",
    "    First index is our original index. Second index is \"match\" which is a running\n",
    "    total of the number of occurences of hashtags and mentions for a particular \n",
    "    tweet. \"\"\"\n",
    "handles_hashtags = tweets.text.str.extractall(pattern)\n",
    "\n",
    "# make the dataframe look nice \n",
    "handles_hashtags.columns = ['handles', 'hashtags']\n",
    "handles_hashtags = handles_hashtags.reset_index().set_index('level_0')\n",
    "del handles_hashtags.index.name\n",
    "handles_hashtags.drop(['match'], axis=1, inplace=True)\n",
    "\n",
    "# stack handles and hashtags into one column\n",
    "handles_hashtags = pd.concat([handles_hashtags.handles, handles_hashtags.hashtags]).dropna().to_frame(name='handles_hashtags')\n",
    "\n",
    "tweets = tweets.join(handles_hashtags, how='inner').reset_index()\n",
    "tweets.drop(['text'], axis=1, inplace=True)\n",
    "\n",
    "del handles_hashtags\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keep active users with at least 20 distinct hashtags/handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns users along with the distinct hashtags/handles they've used\n",
    "handles_hashtags_distinct = tweets.groupby('user_id')['handles_hashtags'].unique().to_frame()\n",
    "# retrieve only those who have used 20 or more distinct handles/hashtags\n",
    "users_active = handles_hashtags_distinct[handles_hashtags_distinct.handles_hashtags.str.len() > 19]\n",
    "\n",
    "del handles_hashtags_distinct\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' returns users along with all the hashtags and handles (including duplicates) they've used \n",
    "    (each occurrence of a hashtag/handle will also show up in the list) '''\n",
    "handles_hashtags_all = tweets.reset_index().groupby('user_id')['handles_hashtags'].apply(list).to_frame()\n",
    "\n",
    "users_active = users_active.join(handles_hashtags_all, lsuffix='_distinct', rsuffix='_all', how='inner')\n",
    "\n",
    "del handles_hashtags_all\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert each list of handles/hashtags into a string\n",
    "users_active['handles_hashtags_stringified'] = users_active['handles_hashtags_all'].apply(lambda x: ' '.join(map(str, x)))\n",
    "\n",
    "# list of strings, each containing all of the handles and hashtags for a user\n",
    "corpus = list(users_active['handles_hashtags_stringified'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hashtags/handles that have been used by at least 20 distinct users (min_df=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructs a dataframe with only the handles/hashtags used by 20 users \n",
    "vectorizer = sk_text.CountVectorizer(min_df=20, max_features=100, lowercase=True, encoding='ISO-8859-1')\n",
    "matrix = vectorizer.fit_transform(corpus)\n",
    "df_idx_id = pd.DataFrame(matrix.toarray(), index=users_active.index, columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_altright_anew</th>\n",
       "      <th>_carja</th>\n",
       "      <th>_cfj_</th>\n",
       "      <th>_makada_</th>\n",
       "      <th>_proud_american</th>\n",
       "      <th>_realvalentina_</th>\n",
       "      <th>a_miller48</th>\n",
       "      <th>abbydphillip</th>\n",
       "      <th>abbymartin</th>\n",
       "      <th>abbymartinm</th>\n",
       "      <th>...</th>\n",
       "      <th>zaibatsunews</th>\n",
       "      <th>zaidjilani</th>\n",
       "      <th>zekejmiller</th>\n",
       "      <th>zerohedge</th>\n",
       "      <th>zhaabowekwe</th>\n",
       "      <th>zigmanfreud</th>\n",
       "      <th>zika</th>\n",
       "      <th>zimmermanrob</th>\n",
       "      <th>zip90210</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2426</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14763</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4036 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         _altright_anew  _carja  _cfj_  _makada_  _proud_american  \\\n",
       "user_id                                                             \n",
       "1644     0               0       0      0         0                 \n",
       "1737     0               0       0      0         0                 \n",
       "2391     0               0       0      0         0                 \n",
       "2426     0               0       0      0         0                 \n",
       "14763    0               0       0      0         0                 \n",
       "\n",
       "         _realvalentina_  a_miller48  abbydphillip  abbymartin  abbymartinm  \\\n",
       "user_id                                                                       \n",
       "1644     0                0           0             0           0             \n",
       "1737     0                0           0             0           0             \n",
       "2391     0                0           0             0           0             \n",
       "2426     0                0           0             0           0             \n",
       "14763    0                0           0             0           0             \n",
       "\n",
       "             ...        zaibatsunews  zaidjilani  zekejmiller  zerohedge  \\\n",
       "user_id      ...                                                           \n",
       "1644         ...        0             0           0            0           \n",
       "1737         ...        0             0           0            0           \n",
       "2391         ...        0             0           0            0           \n",
       "2426         ...        0             0           0            0           \n",
       "14763        ...        0             0           0            0           \n",
       "\n",
       "         zhaabowekwe  zigmanfreud  zika  zimmermanrob  zip90210  retweet_count  \n",
       "user_id                                                                         \n",
       "1644     0            0            0     0             0         6              \n",
       "1737     0            0            0     0             0         4              \n",
       "2391     0            0            0     0             0         18             \n",
       "2426     0            0            0     0             0         199            \n",
       "14763    0            0            0     0             0         9              \n",
       "\n",
       "[5 rows x 4036 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows are users, columns are hashtags/handles\n",
    "# values are frequency of a handle/hashtag\n",
    "df_idx_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# represent each handle/hashtag as an integer\n",
    "train_df = df_idx_id.transpose().reset_index(drop=True).transpose()\n",
    "\n",
    "del df_idx_id\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_table('./data/clinton_trump_user_classes.txt', \n",
    "                       names=['user_id', 'label'])\n",
    "labels.set_index('user_id', inplace=True)\n",
    "train_df = labels.join(train_df, how='inner')\n",
    "y = train_df['label']\n",
    "train_df.drop('label', axis=1, inplace=True)\n",
    "\n",
    "del labels\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_df, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13652, 4036)\n",
      "(3414, 4036)\n",
      "(13652,)\n",
      "(3414,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = preprocessing.StandardScaler()\n",
    "X_train_scaled = std_scaler.fit_transform(X_train)\n",
    "X_test_scaled = std_scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = SVC(C=1, kernel='rbf', degree=3, \n",
    "              gamma='auto', coef0=0.0, shrinking=True, \n",
    "              probability=False, tol=0.001, cache_size=200, \n",
    "              class_weight=None, verbose=False, max_iter=-1, \n",
    "              decision_function_shape='ovr', random_state=42)\n",
    "svm_clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_clf.predict(X_test_scaled)\n",
    "print(metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(criterion='gini', \n",
    "                                  splitter='best', \n",
    "                                  max_depth=None, \n",
    "                                  min_samples_split=2, \n",
    "                                  min_samples_leaf=1, \n",
    "                                  min_weight_fraction_leaf=0.0, \n",
    "                                  max_features=None, \n",
    "                                  random_state=42, \n",
    "                                  max_leaf_nodes=99, \n",
    "                                  min_impurity_decrease=0.0, \n",
    "                                  min_impurity_split=None, \n",
    "                                  class_weight=None, \n",
    "                                  presort=False)\n",
    "tree_clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree_clf.predict(X_test_scaled)\n",
    "print(metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kNN Classification with grid search for best k and 5-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = list(range(1, 20))\n",
    "params = {'n_neighbors': k_range}\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_grid_search_cv = GridSearchCV(knn, \n",
    "                                  params, cv=5, n_jobs=-1, \n",
    "                                  verbose=1, scoring='f1_weighted')\n",
    "\n",
    "knn_grid_search_cv.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_range, means)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('F1 score based on Cross-Validation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knn_grid_search_cv.best_score_)\n",
    "print(knn_grid_search_cv.best_params_)\n",
    "print(knn_grid_search_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_grid_search_cv.predict(X_test_scaled)\n",
    "print(metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
