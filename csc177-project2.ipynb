{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSUS - CSc 177-02 Data Warehousing and Data Mining - Project 1: Clustering  \n",
    "### 2016 U.S. presidential election Twitter analysis  \n",
    "\n",
    "**Group members: Aaron Enberg, Nima Sarrafzadeh, Kyne Liu**  \n",
    "**Professor: Haiquan (Victor) Chen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import (\n",
    "    preprocessing,  \n",
    "    cluster as sk_cluster,\n",
    "    metrics as metrics\n",
    ")\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score,\n",
    "    GridSearchCV\n",
    ")\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column_names = ['name', 'screen_name', 'user_id', \n",
    "                'followers_count', 'friends_count', \n",
    "                'location', 'description', 'created_at', \n",
    "                'status_id', 'language', 'place', \n",
    "                'retweet_count', 'favorite_count', 'text']\n",
    "\n",
    "tweets = pd.read_table('data/clinton_trump_tweets.txt', names=column_names, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5250980, 14)\n",
      "name               object\n",
      "screen_name        object\n",
      "user_id            int64 \n",
      "followers_count    int64 \n",
      "friends_count      int64 \n",
      "location           object\n",
      "description        object\n",
      "created_at         object\n",
      "status_id          int64 \n",
      "language           object\n",
      "place              object\n",
      "retweet_count      int64 \n",
      "favorite_count     int64 \n",
      "text               object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(tweets.shape)\n",
    "print(tweets.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1519696717</td>\n",
       "      <td>132</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>@NWAJimmy I've read it now though brother. Was pretty spot on Lots of bright spots but a lot to work on. Exactly as an exhibition should be!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109945090</td>\n",
       "      <td>2154</td>\n",
       "      <td>2034</td>\n",
       "      <td>1937</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @wikileaks: New poll puts Pirate Party on course to win Iceland's national elections on Saturday. https://t.co/edTqjeJaQ6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1450086582</td>\n",
       "      <td>797</td>\n",
       "      <td>1188</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@gaystoner821 I think New Orleans spoiled me with food. I need to try and branch out in BR.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>167177185</td>\n",
       "      <td>204</td>\n",
       "      <td>448</td>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @LOLGOP: ACA needs fixes but know da facts:  *70% can get covered in marketplaces for under $75/month  *Hikes affect 3% *GOP will uninsu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1191022351</td>\n",
       "      <td>775</td>\n",
       "      <td>154</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @FastCompany: Alphabet shares soar on better-than-expected earnings as mobile video strategy pays off https://t.co/bokbXngMJt https://t.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  followers_count  friends_count  retweet_count  favorite_count  \\\n",
       "0  1519696717  132              263            0              1                \n",
       "1  109945090   2154             2034           1937           0                \n",
       "2  1450086582  797              1188           0              0                \n",
       "3  167177185   204              448            891            0                \n",
       "4  1191022351  775              154            7              0                \n",
       "\n",
       "                                                                                                                                           text  \n",
       "0  @NWAJimmy I've read it now though brother. Was pretty spot on Lots of bright spots but a lot to work on. Exactly as an exhibition should be!  \n",
       "1  RT @wikileaks: New poll puts Pirate Party on course to win Iceland's national elections on Saturday. https://t.co/edTqjeJaQ6                  \n",
       "2  @gaystoner821 I think New Orleans spoiled me with food. I need to try and branch out in BR.                                                   \n",
       "3  RT @LOLGOP: ACA needs fixes but know da facts:  *70% can get covered in marketplaces for under $75/month  *Hikes affect 3% *GOP will uninsu   \n",
       "4  RT @FastCompany: Alphabet shares soar on better-than-expected earnings as mobile video strategy pays off https://t.co/bokbXngMJt https://t.   "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.drop(['name', 'screen_name',   \n",
    "            'description', 'created_at',\n",
    "            'status_id', 'language', \n",
    "            'place', 'location'], axis=1, inplace=True)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lines that start with \"RT\" followed by a space\n",
    "pattern = r'^RT\\s'\n",
    " \n",
    "# matches retweets and removes them\n",
    "tweets = tweets[tweets.text.str.match(pattern) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2416818, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract all handles and hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# match all hashtags and handles in a tweet, ignoring possible email addresses\n",
    "pattern = r'(?<=^|(?<=[^a-zA-Z0-9-\\.]))@([A-Za-z_]+[A-Za-z0-9_]+)|(?<=^|(?<=[^a-zA-Z0-9-\\.]))#([A-Za-z_]+[A-Za-z0-9_]+)'\n",
    "\n",
    "\"\"\" returns a DataFrame with a MultiIndex:\n",
    "    First index is our original index. Second index is \"match\" which is a running\n",
    "    total of the number of occurences of hashtags and mentions for a particular \n",
    "    tweet. \"\"\"\n",
    "handles_hashtags = tweets.text.str.extractall(pattern)\n",
    "\n",
    "# make the dataframe look nice \n",
    "handles_hashtags.columns = ['handles', 'hashtags']\n",
    "handles_hashtags = handles_hashtags.reset_index().set_index('level_0')\n",
    "del handles_hashtags.index.name\n",
    "handles_hashtags.drop(['match'], axis=1, inplace=True)\n",
    "\n",
    "# stack handles and hashtags into one column\n",
    "handles_hashtags = pd.concat([handles_hashtags.handles, handles_hashtags.hashtags]).dropna().to_frame(name='handles_hashtags')\n",
    "\n",
    "tweets = tweets.join(handles_hashtags, how='inner').reset_index()\n",
    "tweets.drop(['text'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keep active users with at least 20 distinct hashtags/handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns users along with the distinct hashtags/handles they've used\n",
    "handles_hashtags_distinct = tweets.groupby('user_id')['handles_hashtags'].unique().to_frame()\n",
    "# retrieve only those who have used 20 or more distinct handles/hashtags\n",
    "users_active = handles_hashtags_distinct[handles_hashtags_distinct.handles_hashtags.str.len() > 19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' returns users along with all the hashtags and handles (including duplicates) they've used \n",
    "    (each occurrence of a hashtag/handle will also show up in the list) '''\n",
    "handles_hashtags_all = tweets.reset_index().groupby('user_id')['handles_hashtags'].apply(list).to_frame()\n",
    "\n",
    "users_active = users_active.join(handles_hashtags_all, lsuffix='_distinct', rsuffix='_all', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         retweet_count\n",
       "user_id               \n",
       "150      0            \n",
       "1437     0            \n",
       "1512     0            \n",
       "1644     6            \n",
       "1668     0            "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct a dataframe with totals for retweets, favorites, followers, and friends for each user\n",
    "tweets.drop(['handles_hashtags', 'index'], axis=1, inplace=True)\n",
    "tweets.set_index('user_id', inplace=True)\n",
    "count_retweets_favorites = tweets.groupby(tweets.index)['retweet_count', 'favorite_count'].sum()\n",
    "tweets.drop(['retweet_count', 'favorite_count'], axis=1, inplace=True)\n",
    "count_followers_friends = tweets[~tweets.index.duplicated(keep='first')]\n",
    "users_active_stats = count_retweets_favorites.join(count_followers_friends, how='inner')\n",
    "users_active_stats.drop(['favorite_count', 'followers_count', 'friends_count'], axis=1, inplace=True)\n",
    "users_active_stats.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert each list of handles/hashtags into a string\n",
    "users_active['handles_hashtags_stringified'] = users_active['handles_hashtags_all'].apply(lambda x: ' '.join(map(str, x)))\n",
    "\n",
    "# list of strings, each containing all of the handles and hashtags for a user\n",
    "corpus = list(users_active['handles_hashtags_stringified'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hashtags/handles that have been used by at least 20 distinct users (min_df=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructs a dataframe with only the handles/hashtags used by 20 users \n",
    "vectorizer = sk_text.CountVectorizer(min_df=20, lowercase=True, encoding='ISO-8859-1')\n",
    "matrix = vectorizer.fit_transform(corpus)\n",
    "df_idx_id = pd.DataFrame(matrix.toarray(), index=users_active.index, columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_altright_anew</th>\n",
       "      <th>_carja</th>\n",
       "      <th>_cfj_</th>\n",
       "      <th>_makada_</th>\n",
       "      <th>_proud_american</th>\n",
       "      <th>_realvalentina_</th>\n",
       "      <th>a_miller48</th>\n",
       "      <th>abbydphillip</th>\n",
       "      <th>abbymartin</th>\n",
       "      <th>abbymartinm</th>\n",
       "      <th>...</th>\n",
       "      <th>zaibatsunews</th>\n",
       "      <th>zaidjilani</th>\n",
       "      <th>zekejmiller</th>\n",
       "      <th>zerohedge</th>\n",
       "      <th>zhaabowekwe</th>\n",
       "      <th>zigmanfreud</th>\n",
       "      <th>zika</th>\n",
       "      <th>zimmermanrob</th>\n",
       "      <th>zip90210</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2426</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14763</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4036 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         _altright_anew  _carja  _cfj_  _makada_  _proud_american  \\\n",
       "user_id                                                             \n",
       "1644     0               0       0      0         0                 \n",
       "1737     0               0       0      0         0                 \n",
       "2391     0               0       0      0         0                 \n",
       "2426     0               0       0      0         0                 \n",
       "14763    0               0       0      0         0                 \n",
       "\n",
       "         _realvalentina_  a_miller48  abbydphillip  abbymartin  abbymartinm  \\\n",
       "user_id                                                                       \n",
       "1644     0                0           0             0           0             \n",
       "1737     0                0           0             0           0             \n",
       "2391     0                0           0             0           0             \n",
       "2426     0                0           0             0           0             \n",
       "14763    0                0           0             0           0             \n",
       "\n",
       "             ...        zaibatsunews  zaidjilani  zekejmiller  zerohedge  \\\n",
       "user_id      ...                                                           \n",
       "1644         ...        0             0           0            0           \n",
       "1737         ...        0             0           0            0           \n",
       "2391         ...        0             0           0            0           \n",
       "2426         ...        0             0           0            0           \n",
       "14763        ...        0             0           0            0           \n",
       "\n",
       "         zhaabowekwe  zigmanfreud  zika  zimmermanrob  zip90210  retweet_count  \n",
       "user_id                                                                         \n",
       "1644     0            0            0     0             0         6              \n",
       "1737     0            0            0     0             0         4              \n",
       "2391     0            0            0     0             0         18             \n",
       "2426     0            0            0     0             0         199            \n",
       "14763    0            0            0     0             0         9              \n",
       "\n",
       "[5 rows x 4036 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# append retweet/favorite counts and friend/follower counts to end of each record\n",
    "df_idx_id = df_idx_id.join(users_active_stats, how='inner')\n",
    "\n",
    "# rows are users, columns are hashtags/handles\n",
    "# values are frequency of a handle/hashtag\n",
    "df_idx_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# represent each handle/hashtag as an integer\n",
    "df_idx_hashtags = df_idx_id.transpose().reset_index(drop=True).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_table('./data/clinton_trump_user_classes.txt', \n",
    "                       names=['user_id', 'label'])\n",
    "labels.set_index('user_id', inplace=True)\n",
    "df_idx_hashtags = labels.join(df_idx_hashtags, how='inner')\n",
    "y = df_idx_hashtags['label']\n",
    "df_idx_hashtags.drop('label', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_idx_hashtags, \n",
    "                                                    y, test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13652, 4036)\n",
      "(3414, 4036)\n",
      "(13652,)\n",
      "(3414,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = preprocessing.StandardScaler()\n",
    "X_train_std = std_scaler.fit_transform(X_train)\n",
    "X_test_std = std_scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=42, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf = SVC(C=1, kernel='rbf', degree=3, \n",
    "              gamma='auto', coef0=0.0, shrinking=True, \n",
    "              probability=False, tol=0.001, cache_size=200, \n",
    "              class_weight=None, verbose=False, max_iter=-1, \n",
    "              decision_function_shape='ovr', random_state=42)\n",
    "svm_clf.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7768281101614435\n"
     ]
    }
   ],
   "source": [
    "y_pred = svm_clf.predict(X_test_std)\n",
    "print(metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=99,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier(criterion='gini', \n",
    "                                  splitter='best', \n",
    "                                  max_depth=None, \n",
    "                                  min_samples_split=2, \n",
    "                                  min_samples_leaf=1, \n",
    "                                  min_weight_fraction_leaf=0.0, \n",
    "                                  max_features=None, \n",
    "                                  random_state=42, \n",
    "                                  max_leaf_nodes=99, \n",
    "                                  min_impurity_decrease=0.0, \n",
    "                                  min_impurity_split=None, \n",
    "                                  class_weight=None, \n",
    "                                  presort=False)\n",
    "tree_clf.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7604364326375712\n"
     ]
    }
   ],
   "source": [
    "y_pred = tree_clf.predict(X_test_std)\n",
    "print(metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kNN Classification with grid search for best k and 5-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 19 candidates, totalling 95 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 79.2min\n",
      "[Parallel(n_jobs=-1)]: Done  95 out of  95 | elapsed: 245.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_neighbors': list(range(1, 20))}\n",
    "knn_grid_search_cv = GridSearchCV(KNeighborsClassifier(), params, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "knn_grid_search_cv.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=12, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6596103135071785"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_grid_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7226118500604595\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn_grid_search_cv.best_estimator_.predict(X_test_std)\n",
    "print(metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaron/.virtualenvs/CSc177/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/aaron/.virtualenvs/CSc177/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/aaron/.virtualenvs/CSc177/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/aaron/.virtualenvs/CSc177/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/aaron/.virtualenvs/CSc177/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/aaron/.virtualenvs/CSc177/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/aaron/.virtualenvs/CSc177/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([6.45201759, 5.97357082, 5.49793668, 4.92522311, 5.34484549,\n",
       "        5.38179779, 5.24446721, 5.0155261 , 5.0378087 , 4.92368097,\n",
       "        5.05490537, 5.05236354, 5.01986804, 5.19169617, 5.0062984 ,\n",
       "        5.04905152, 4.91266131, 4.90150666, 5.12212958]),\n",
       " 'mean_score_time': array([144.96333842, 189.55677805, 209.5252883 , 217.93238144,\n",
       "        232.22594905, 245.38913784, 252.83323212, 257.58317728,\n",
       "        261.59472752, 265.31801805, 271.72247858, 274.07894468,\n",
       "        274.71545439, 276.571071  , 277.0685307 , 277.74630294,\n",
       "        278.8623404 , 282.13796101, 273.6343677 ]),\n",
       " 'mean_test_score': array([0.61610021, 0.59749487, 0.64305596, 0.63397304, 0.65470261,\n",
       "        0.64767067, 0.65484911, 0.65199238, 0.65792558, 0.65719309,\n",
       "        0.65865807, 0.65961031, 0.65902432, 0.65777908, 0.6552886 ,\n",
       "        0.65433636, 0.65089364, 0.65265163, 0.64825667]),\n",
       " 'mean_train_score': array([0.98632067, 0.82255341, 0.80870942, 0.78288893, 0.76796433,\n",
       "        0.76193954, 0.74741799, 0.74646575, 0.73262168, 0.7355882 ,\n",
       "        0.72558976, 0.72987478, 0.71698296, 0.72130471, 0.70876083,\n",
       "        0.71445598, 0.70150913, 0.70568432, 0.69434897]),\n",
       " 'param_n_neighbors': masked_array(data=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,\n",
       "                    17, 18, 19],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_neighbors': 1},\n",
       "  {'n_neighbors': 2},\n",
       "  {'n_neighbors': 3},\n",
       "  {'n_neighbors': 4},\n",
       "  {'n_neighbors': 5},\n",
       "  {'n_neighbors': 6},\n",
       "  {'n_neighbors': 7},\n",
       "  {'n_neighbors': 8},\n",
       "  {'n_neighbors': 9},\n",
       "  {'n_neighbors': 10},\n",
       "  {'n_neighbors': 11},\n",
       "  {'n_neighbors': 12},\n",
       "  {'n_neighbors': 13},\n",
       "  {'n_neighbors': 14},\n",
       "  {'n_neighbors': 15},\n",
       "  {'n_neighbors': 16},\n",
       "  {'n_neighbors': 17},\n",
       "  {'n_neighbors': 18},\n",
       "  {'n_neighbors': 19}],\n",
       " 'rank_test_score': array([18, 19, 16, 17,  9, 15,  8, 12,  4,  6,  3,  1,  2,  5,  7, 10, 13,\n",
       "        11, 14], dtype=int32),\n",
       " 'split0_test_score': array([0.60710363, 0.59245698, 0.64445258, 0.62541194, 0.64518491,\n",
       "        0.63749542, 0.64518491, 0.64335408, 0.65433907, 0.65250824,\n",
       "        0.6572684 , 0.65763457, 0.66312706, 0.6605639 , 0.6550714 ,\n",
       "        0.65250824, 0.65324057, 0.65177591, 0.64994508]),\n",
       " 'split0_train_score': array([0.98544089, 0.81668345, 0.81366175, 0.78088087, 0.77016757,\n",
       "        0.76229283, 0.75313616, 0.74929036, 0.73876019, 0.74013369,\n",
       "        0.73116015, 0.73445655, 0.72236975, 0.72649025, 0.71357934,\n",
       "        0.72429265, 0.70625401, 0.71028294, 0.6941672 ]),\n",
       " 'split1_test_score': array([0.63566459, 0.60710363, 0.65140974, 0.64445258, 0.66312706,\n",
       "        0.6594654 , 0.66605639, 0.65983156, 0.65873306, 0.66166239,\n",
       "        0.66569022, 0.66825339, 0.67081655, 0.67045038, 0.66569022,\n",
       "        0.66312706, 0.65433907, 0.6594654 , 0.6539729 ]),\n",
       " 'split1_train_score': array([0.98626499, 0.82483289, 0.80761835, 0.78335317, 0.76192656,\n",
       "        0.75579159, 0.74306382, 0.74553612, 0.73106858, 0.73125172,\n",
       "        0.72548301, 0.72740592, 0.71696731, 0.72356011, 0.71559381,\n",
       "        0.71687574, 0.70735281, 0.71064921, 0.70286604]),\n",
       " 'split2_test_score': array([0.62454212, 0.60952381, 0.64725275, 0.63882784, 0.66043956,\n",
       "        0.65164835, 0.65824176, 0.64798535, 0.66153846, 0.65934066,\n",
       "        0.66556777, 0.66556777, 0.65897436, 0.65787546, 0.65421245,\n",
       "        0.65201465, 0.65018315, 0.65238095, 0.64798535]),\n",
       " 'split2_train_score': array([0.98608313, 0.81935543, 0.80424831, 0.77980223, 0.76469511,\n",
       "        0.7607581 , 0.74446072, 0.74528475, 0.72990295, 0.73448086,\n",
       "        0.72202893, 0.72559971, 0.71690167, 0.72047244, 0.70728804,\n",
       "        0.71159128, 0.70133675, 0.70646402, 0.69694195]),\n",
       " 'split3_test_score': array([0.60769231, 0.58168498, 0.63369963, 0.63663004, 0.65824176,\n",
       "        0.64835165, 0.65824176, 0.66703297, 0.66190476, 0.66373626,\n",
       "        0.66153846, 0.66117216, 0.65897436, 0.66263736, 0.65714286,\n",
       "        0.65970696, 0.65054945, 0.65567766, 0.65054945]),\n",
       " 'split3_train_score': array([0.98690716, 0.82594763, 0.81157297, 0.78731002, 0.77339315,\n",
       "        0.76689251, 0.75059513, 0.74894708, 0.73530489, 0.73741073,\n",
       "        0.72944516, 0.73475554, 0.71919062, 0.72285296, 0.71049258,\n",
       "        0.7161692 , 0.7040835 , 0.709577  , 0.69840689]),\n",
       " 'split4_test_score': array([0.60549451, 0.5967033 , 0.63846154, 0.62454212, 0.64652015,\n",
       "        0.64139194, 0.64652015, 0.64175824, 0.65311355, 0.64871795,\n",
       "        0.64322344, 0.64542125, 0.64322344, 0.63736264, 0.64432234,\n",
       "        0.64432234, 0.64615385, 0.64395604, 0.63882784]),\n",
       " 'split4_train_score': array([0.98690716, 0.82594763, 0.80644571, 0.78309833, 0.76963926,\n",
       "        0.76396264, 0.7458341 , 0.74327046, 0.72807178, 0.73466398,\n",
       "        0.71983153, 0.7271562 , 0.70948544, 0.71314778, 0.69685039,\n",
       "        0.70335103, 0.68851859, 0.69144845, 0.67936275]),\n",
       " 'std_fit_time': array([0.77356656, 0.62104728, 0.82163291, 0.10600896, 0.43913416,\n",
       "        0.80256974, 0.39307505, 0.16426062, 0.13874682, 0.08452859,\n",
       "        0.06714237, 0.09741352, 0.16419195, 0.24754309, 0.1856681 ,\n",
       "        0.18039358, 0.0725818 , 0.03998973, 0.22145415]),\n",
       " 'std_score_time': array([3.8777686 , 2.78051636, 8.26463368, 1.07003658, 1.04148544,\n",
       "        2.82122309, 2.56770746, 3.17876039, 3.45193818, 2.65186136,\n",
       "        5.00872831, 4.40149955, 7.106331  , 2.89741475, 4.66811617,\n",
       "        1.61671279, 3.40462128, 4.05534094, 9.74168339]),\n",
       " 'std_test_score': array([0.01198506, 0.01012868, 0.00629279, 0.00778083, 0.00740227,\n",
       "        0.00772534, 0.0078921 , 0.00982919, 0.00362085, 0.00567745,\n",
       "        0.00831407, 0.00797306, 0.00900622, 0.01103388, 0.00682791,\n",
       "        0.00655943, 0.00284494, 0.00513879, 0.00509418]),\n",
       " 'std_train_score': array([0.00055163, 0.00381892, 0.00343342, 0.00258323, 0.00410546,\n",
       "        0.00368626, 0.00382112, 0.0023067 , 0.00388294, 0.00299561,\n",
       "        0.00428349, 0.00391348, 0.00424525, 0.00450781, 0.00658687,\n",
       "        0.00688588, 0.00681284, 0.00726936, 0.00800438])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_grid_search_cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
